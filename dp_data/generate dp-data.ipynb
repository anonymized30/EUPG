{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd30bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unittest import TestCase\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from diffprivlib.mechanisms import ExponentialCategorical\n",
    "from diffprivlib.mechanisms import Laplace\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from dp_pix import*\n",
    "from load_dp_cifar10_dataset import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09dea192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a batch of original and DP-obfuscated images\n",
    "def show_images(original, dp_images, epsilons):\n",
    "    fig, axes = plt.subplots(1, len(epsilons) + 1, figsize=(12, 6))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(np.transpose(original.numpy(), (1, 2, 0)))\n",
    "    axes[0].set_title(\"Original\")\n",
    "    \n",
    "    # DP-Pix images for each epsilon\n",
    "    for idx, epsilon in enumerate(epsilons):\n",
    "        axes[idx + 1].imshow(np.transpose(dp_images[epsilon].numpy(), (1, 2, 0)))\n",
    "        axes[idx + 1].set_title(f\"eps={epsilon}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to save the DP-Pix dataset for each epsilon\n",
    "def save_dp_dataset(trainloader, epsilons, block_size, m):\n",
    "    for epsilon in epsilons:\n",
    "        # Create a directory for each epsilon value\n",
    "        output_dir = f'cifar10/dp_cifar10_eps_{epsilon}'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        print(f\"Processing DP-Pix with epsilon = {epsilon}\")\n",
    "        \n",
    "        for idx, (images, labels) in tqdm(enumerate(trainloader)):\n",
    "            image = images[0]  # Take the first image from the batch\n",
    "            dp_image = dp_pix(image, block_size, m, epsilon)\n",
    "            \n",
    "            # Save the DP image to the corresponding directory\n",
    "            save_path = os.path.join(output_dir, f'{idx}.png')\n",
    "            save_image(dp_image, save_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa06902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adult dataset\n",
    "# times = []\n",
    "# columns = [\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "#            \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "#            \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "# data = pd.read_csv('adult/adult.data', names=columns, sep=r' *, *', engine='python', na_values='?')\n",
    "# # Drop useless columns\n",
    "# data.dropna(inplace=True)\n",
    "# # Reset the index\n",
    "# data.reset_index(drop=True, inplace=True)\n",
    "# # Load utilities\n",
    "# file_path = 'adult/utilities.pkl'\n",
    "# with open(file_path, 'rb') as file:\n",
    "#     utility_dict = pickle.load(file)\n",
    "    \n",
    "# EPS = [0.5, 2.5, 5., 25., 50., 100.]\n",
    "# for eps in EPS:\n",
    "#     t0 = time.time()\n",
    "#     data_copy = data.copy()\n",
    "#     for attribute in data_copy.columns:\n",
    "#         if attribute in utility_dict.keys():\n",
    "#             utility_list = utility_dict[attribute]\n",
    "#             try:\n",
    "#                 mech = ExponentialCategorical(epsilon = eps/(len(data_copy.columns)-3), utility_list = utility_list)\n",
    "#             except:\n",
    "#                 utility_list = [[str(key1), str(key2), utility_value] for key1, key2, utility_value in utility_list]\n",
    "#                 mech = ExponentialCategorical(epsilon = eps/(len(data_copy.columns)-3), utility_list = utility_list)\n",
    "#             data_copy[attribute] = data_copy[attribute].apply(lambda x: mech.randomise(str(x))).astype(data_copy[attribute].dtype)\n",
    "    \n",
    "#     data_copy.to_csv('adult/dp_adult_eps={}.csv'.format(eps), index=False)\n",
    "#     times.append(time.time() - t0)\n",
    "# mean_time = np.mean(times)\n",
    "# std_time = np.std(times)\n",
    "# print('Anonymizing D time:{:0.2f}(±{:0.2f})'.format(mean_time, std_time))\n",
    "# print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed73a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding and utility calculation runtime: 167.43188667297363\n",
    "# Anonymizing D time:19.52(±3.52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4e9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Heart dataset\n",
    "# times = []\n",
    "# data = pd.read_csv('heart/cardio_train.csv', sep=';')\n",
    "# data.drop(columns=['id'], inplace=True)\n",
    "# data.dropna(inplace=True)\n",
    "# # Reset the index\n",
    "# data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# EPS = [0.5, 2.5, 5., 25., 50., 100., 250, 500, 1000]\n",
    "# for eps in EPS:\n",
    "#     t0 = time.time()\n",
    "#     data_copy = data.copy()\n",
    "#     for attribute in data_copy.columns:\n",
    "#         if 'cardio' in attribute:continue\n",
    "#         a, b = data_copy[attribute].min(), data_copy[attribute].max()\n",
    "#         sensitivity = b - a\n",
    "#         mech = Laplace(epsilon = eps/(len(data_copy.columns)-1), sensitivity=sensitivity)\n",
    "#         data_copy[attribute] = data_copy[attribute].apply(lambda x: mech.randomise(x)).astype(data_copy[attribute].dtype)\n",
    "#         data_copy[attribute] = data_copy[attribute].apply(lambda x: np.clip(x, a, b)).astype(data_copy[attribute].dtype)\n",
    "    \n",
    "#     data_copy.to_csv('heart/dp_heart_eps={}.csv'.format(eps), index=False)\n",
    "#     times.append(time.time() - t0)\n",
    "    \n",
    "# mean_time = np.mean(times)\n",
    "# std_time = np.std(times)\n",
    "# print('Anonymizing D time:{:0.2f}(±{:0.2f})'.format(mean_time, std_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f4578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Credit dataset\n",
    "# times = []\n",
    "# data=pd.read_csv('GiveMeSomeCredit/cs-training.csv')\n",
    "# data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# data.dropna(inplace=True)\n",
    "# # Reset the index\n",
    "# data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# EPS = [0.5, 2.5, 5., 25., 50., 100.]\n",
    "# for eps in EPS:\n",
    "#     t0 = time.time()\n",
    "#     data_copy = data.copy()\n",
    "#     for attribute in data_copy.columns:\n",
    "#         if 'SeriousDlqin2yrs' in attribute:continue\n",
    "#         a, b = data_copy[attribute].min(), data_copy[attribute].max()\n",
    "#         sensitivity = b - a\n",
    "#         mech = Laplace(epsilon = eps/(len(data_copy.columns)-1), sensitivity=sensitivity)\n",
    "#         data_copy[attribute] = data_copy[attribute].apply(lambda x: mech.randomise(x)).astype(data_copy[attribute].dtype)\n",
    "#         data_copy[attribute] = data_copy[attribute].apply(lambda x: np.clip(x, a, b)).astype(data_copy[attribute].dtype)\n",
    "    \n",
    "#     data_copy.to_csv('GiveMeSomeCredit/dp_credit_eps={}.csv'.format(eps), index=False)\n",
    "#     times.append(time.time() - t0)\n",
    "    \n",
    "# mean_time = np.mean(times)\n",
    "# std_time = np.std(times)\n",
    "# print('Anonymizing D time:{:0.2f}(±{:0.2f})'.format(mean_time, std_time))\n",
    "# print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4e43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 dataset\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='../data', train=True, download=False, transform=transform)\n",
    "labels = trainset.targets\n",
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=False)\n",
    "\n",
    "# # Parameters\n",
    "# epsilons = [0.5, 2.5, 5., 25., 50., 100.]  # Epsilon values\n",
    "# m = 16          # Maximum number of different pixels in the image for DP\n",
    "# block_size = 4  # Size of pixelation block (b)\n",
    "\n",
    "# for eps in epsilons:\n",
    "#     t0 = time.time()\n",
    "#     # Process the trainset and save DP obfuscated datasets for each epsilon\n",
    "#     save_dp_dataset(trainloader, [eps], block_size, m)\n",
    "#     print('Anonymizing D time:{:0.2f}'.format((time.time() - t0)/len([eps])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f63ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m=16, b=16:Anonymizing D time:74.36\n",
    "# m=16, b=8:Anonymizing D time:111.13\n",
    "# m=16, b=6: Anonymizing D time:137.70\n",
    "# m=16, b=4:Anonymizing D time:158.96\n",
    "# m=8, b=4: Anonymizing D time:172.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=10, shuffle=False)\n",
    "# Display a batch of original CIFAR-10 images\n",
    "for _, (images, labels) in enumerate(train_loader):\n",
    "    # Make a grid (2 rows and 5 columns) to display the first 10 images\n",
    "    grid_img = make_grid(images, nrow=5)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))  # Display the image grid\n",
    "#     plt.title(f'Labels: {labels.tolist()}')  # Show labels in the title\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cifar_dp_samples/original_images.png', bbox_inches='tight', pad_inches=0, dpi = 600)\n",
    "    plt.show()\n",
    "    break  # Display just the first batch\n",
    "\n",
    "# Load DP-obfuscated CIFAR-10 dataset with a specific epsilon value\n",
    "epsilon = 100.0  # Specify the epsilon value\n",
    "\n",
    "# Define the transform to convert images to tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Directory path for the corresponding epsilon dataset\n",
    "dataset_dir = f'./cifar10/m16_b4/dp_cifar10_eps_{epsilon}'\n",
    "\n",
    "# Use the original CIFAR-10 labels for DP-obfuscated images\n",
    "labels = trainset.targets\n",
    "\n",
    "# Create a dataset object for the DP-obfuscated dataset\n",
    "dp_dataset = DPCIFAR10Dataset(root_dir=dataset_dir, labels=labels, transform=transform)\n",
    "\n",
    "# Create a DataLoader for the DP-obfuscated dataset\n",
    "dp_loader = DataLoader(dp_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# Step 4: Display a batch of DP-obfuscated images\n",
    "for _, (images, labels) in enumerate(dp_loader):\n",
    "    # Make a grid (2 rows and 5 columns) to display the first 10 images\n",
    "    grid_img = make_grid(images, nrow=5)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))  # Display the image grid\n",
    "#     plt.title(f'DP Labels: {labels.tolist()}')  # Show labels in the title\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cifar_dp_samples/dp_images_eps={}.png'.format(epsilon), bbox_inches='tight', pad_inches=0, dpi = 600)\n",
    "    plt.show()\n",
    "    break  # Display just the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add333d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
