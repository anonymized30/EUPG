{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351db4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506800e0",
   "metadata": {},
   "source": [
    "# Adul dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7138585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15) (16282, 15)\n"
     ]
    }
   ],
   "source": [
    "# | Variable Name    | Role       | Type      | Demographic         | Description          | Units | Missing Values |\n",
    "# |------------------|------------|-----------|---------------------|----------------------|-------|----------------|\n",
    "# | age              | Feature    | Integer   | Age                 | N/A                  |       | no             |\n",
    "# | workclass        | Feature    | Categorical | Income            | Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked | | yes           |\n",
    "# | fnlwgt           | Feature    | Integer   |                     |                      |       | no             |\n",
    "# | education        | Feature    | Categorical | Education Level   | Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool | | no |\n",
    "# | education-num    | Feature    | Integer   | Education Level   |                      |       | no             |\n",
    "# | marital-status   | Feature    | Categorical | Other             | Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse | | no |\n",
    "# | occupation       | Feature    | Categorical | Other             | Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces | | yes |\n",
    "# | relationship     | Feature    | Categorical | Other             | Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried | | no |\n",
    "# | race             | Feature    | Categorical | Race              | White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black | | no |\n",
    "# | sex              | Feature    | Binary    | Sex                 | Female, Male         |       |                |\n",
    "\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "# Read data\n",
    "columns = [\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "           \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "           \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "train_data = pd.read_csv('data/adult/adult.data', names=columns, sep=r' *, *', engine='python', na_values='?')\n",
    "# Drop useless columns\n",
    "train_data.drop(['fnlwgt', 'education'], axis=1, inplace=True)\n",
    "train_data.dropna(inplace=True)\n",
    "# Reset the index\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "nunique = train_data.nunique()\n",
    "types = train_data.dtypes\n",
    "\n",
    "mapping_dict = {}\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in train_data.columns:\n",
    "    mapping_dict[col] = {}\n",
    "    if types[col] == 'object' or nunique[col] < 200:\n",
    "        l_enc = LabelEncoder()\n",
    "        train_data[col] = train_data[col].fillna(\"VV_likely\")\n",
    "        train_data[col] = l_enc.fit_transform(train_data[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "        for i, c in enumerate(l_enc.classes_):\n",
    "             mapping_dict[col][i] = c\n",
    "                \n",
    "\n",
    "features = [ col for col in train_data.columns]\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "n = len(train_data)\n",
    "m = int(0.1*n)\n",
    "idxs = np.arange(n)\n",
    "random.shuffle(idxs)\n",
    "\n",
    "X_train = train_data[features].values[idxs[m:]]\n",
    "X_valid = train_data[features].values[idxs[:m]]\n",
    "\n",
    "# TabNetPretrainer\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=10,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax', # \"sparsemax\",\n",
    "    n_shared_decoder=1, # nb shared glu for decoding\n",
    "    n_indep_decoder=1, # nb independent glu for decoding\n",
    "#     grouped_features=[[0, 1]], # you can group features together here\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "max_epochs = 200 if not os.getenv(\"CI\", False) else 2 # 1000\n",
    "unsupervised_model.fit(\n",
    "    X_train=X_train,\n",
    "    eval_set=[X_valid],\n",
    "    max_epochs=max_epochs , patience=10,\n",
    "    batch_size=2048, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    pretraining_ratio=0.5,\n",
    ") \n",
    "\n",
    "# Extract embeddings\n",
    "_, embedded_X = unsupervised_model.predict(train_data[features].values)\n",
    "\n",
    "attribute_embedding = {col: {} for col in train_data.columns if 'income' not in col}\n",
    "i = 0\n",
    "for col in attribute_embedding:\n",
    "    unique_values = train_data[col].unique()\n",
    "    for unique_val in unique_values:\n",
    "        mask = train_data[col] == unique_val\n",
    "        idx = train_data.index[mask].tolist()[0]\n",
    "        attribute_embedding[col][mapping_dict[col][unique_val]] = embedded_X[idx, i:i+10]\n",
    "    i+=10\n",
    "file_path = 'data/adult/embeddings.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(attribute_embedding, file)\n",
    "# Load the dictionary back from the pickle file\n",
    "with open(file_path, 'rb') as file:\n",
    "    attribute_embedding = pickle.load(file)\n",
    "\n",
    "numrical_attributes = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "file_path = 'data/adult/embeddings.pkl'\n",
    "# Load the dictionary from the pickle file\n",
    "with open(file_path, 'rb') as file:\n",
    "    attribute_embedding = pickle.load(file)\n",
    "\n",
    "utility_dict = {attribute:[] for attribute in attribute_embedding}\n",
    "\n",
    "for attribute in attribute_embedding:\n",
    "    if attribute in numrical_attributes:\n",
    "        array = np.array(list(attribute_embedding[attribute].keys()))\n",
    "        max_a = np.max(array)\n",
    "        utility_list = []\n",
    "        for i in range(len(array)):\n",
    "            for j in range(i+1, len(array)):\n",
    "                utility = (max_a - abs(array[i] - array[j]))/max_a\n",
    "                utility_list.append([array[i], array[j], utility])\n",
    "        \n",
    "        utility_dict[attribute] = utility_list\n",
    "    \n",
    "    else:\n",
    "        values = list(attribute_embedding[attribute].keys())\n",
    "        utility_list = []\n",
    "        for i in range(len(values)):\n",
    "            for j in range(i + 1, len(values)):\n",
    "                vec_i = attribute_embedding[attribute][values[i]].reshape(1, -1)\n",
    "                vec_j = attribute_embedding[attribute][values[j]].reshape(1, -1)\n",
    "                # Compute cosine similarity\n",
    "                utility = (cosine_similarity(vec_i, vec_j)[0][0] + 1)/2\n",
    "                utility_list.append([values[i], values[j], utility])\n",
    "        \n",
    "        utility_dict[attribute] = utility_list\n",
    "\n",
    "file_path = 'data/adult/utilities.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(utility_dict, file)\n",
    "    \n",
    "t = time.time() - t0\n",
    "print('Embedding and utility calculation runtime:', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a44700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32561+16282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding and utility calculation runtime: 167.43188667297363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings per attribute\n",
    "\n",
    "occupation_embeddings = attribute_embedding['marital-status']\n",
    "\n",
    "\n",
    "# Prepare the data for t-SNE\n",
    "occupations = list(occupation_embeddings.keys())\n",
    "embeddings = np.array([occupation_embeddings[occupation] for occupation in occupations])\n",
    "\n",
    "# Determine an appropriate perplexity value (less than the number of samples)\n",
    "perplexity_value = min(30, len(occupations)-1)\n",
    "\n",
    "# Apply PCA and reduce to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c='brown')\n",
    "\n",
    "# Annotate points with occupation names\n",
    "for i, occupation in enumerate(occupations):\n",
    "    plt.annotate(occupation, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]))\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('occupation embeddings')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef82b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
