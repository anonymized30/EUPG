{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "headers = ['age','workclass','fnlwgt','education','education-num','marital-status',\n",
    "           'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "           'hours-per-week','native-country','class']\n",
    "adult = pd.read_csv('adult/adult.data', \n",
    "                    sep=', ', names=headers, na_values='?', engine='python')\n",
    "\n",
    "# Drop all records with missing values\n",
    "adult.dropna(inplace=True)\n",
    "adult.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y = adult['class']\n",
    "X = adult.drop(['fnlwgt', 'class'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load semantic distances from files\n",
    "\n",
    "import os\n",
    "import collections\n",
    "categorical_attributes = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                          'relationship','race','sex','native-country']\n",
    "# path = 'semdist/ontodist/'\n",
    "path = 'semdist/embedist/'\n",
    "\n",
    "distances = {}\n",
    "for categorical_attribute in categorical_attributes:\n",
    "    with open(path+categorical_attribute+'.txt') as f:\n",
    "        contents = list(f)\n",
    "        categories = list(map(str.strip, contents[0].split(',')))\n",
    "        m = []\n",
    "        for line in contents[1:]:\n",
    "            m.append(list(map(float, map(str.strip, line.split(',')))))\n",
    "        d = collections.defaultdict(dict)\n",
    "        for i in range(len(categories)):\n",
    "            for j in range(len(categories)):\n",
    "                d[categories[i]][categories[j]] = m[i][j]\n",
    "        distances[categorical_attribute] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_attr(x, y, attr_pos, categorical_mask, column_names):\n",
    "    if categorical_mask[attr_pos]:\n",
    "        return distances[column_names[attr_pos]][x[attr_pos]][y[attr_pos]]\n",
    "    else:\n",
    "        return abs(float(x[attr_pos]) - float(y[attr_pos]))\n",
    "\n",
    "def dist_record(x, y):\n",
    "    d = []\n",
    "    categorical_mask = [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
    "    column_names =  ['age','workclass','education','education-num','marital-status',\n",
    "           'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "           'hours-per-week','native-country']\n",
    "    for i, cn in enumerate(column_names):\n",
    "        d.append(dist_attr(x, y, i, categorical_mask, column_names))\n",
    "    \n",
    "    ## 0->age \n",
    "    #d.append(dist_attr(x,y,0))\n",
    "    ## 1->workclass  \n",
    "    #d.append(distances['workclass'][x[1]][y[1]])\n",
    "    ## 2->education \n",
    "    #d.append(distances['education'][x[2]][y[2]])\n",
    "    ## 3->education-num   \n",
    "    #d.append(dist_attr(x,y,3))\n",
    "    ## 4->marital-status  \n",
    "    #d.append(distances['marital-status'][x[4]][y[4]])\n",
    "    ## 5->occupation  \n",
    "    #d.append(distances['occupation'][x[5]][y[5]])\n",
    "    ## 6->relationship \n",
    "    #d.append(distances['relationship'][x[6]][y[6]])\n",
    "    ## 7->race    \n",
    "    #d.append(distances['race'][x[7]][y[7]])\n",
    "    ## 8->sex  \n",
    "    #d.append(distances['sex'][x[8]][y[8]])\n",
    "    ## 9->capital-gain  \n",
    "    #d.append(dist_attr(x,y,9))\n",
    "    ##10->capital-loss \n",
    "    #d.append(dist_attr(x,y,10))\n",
    "    ##11->hours-per-week \n",
    "    #d.append(dist_attr(x,y,11))\n",
    "    ##12->native-country  \n",
    "    #d.append(distances['native-country'][x[12]][y[12]])\n",
    "    \n",
    "    return float(sum(d))\n",
    "    \n",
    "def mean_record(D):\n",
    "    d = []\n",
    "    # 0->age \n",
    "    d.append(float(np.mean(D[:,0])))\n",
    "    # 1->workclass  \n",
    "    d.append(mean_semantic(D[:,1], 'workclass'))\n",
    "    # 2->education \n",
    "    d.append(mean_semantic(D[:,2], 'education'))\n",
    "    # 3->education-num   \n",
    "    d.append(float(np.mean(D[:,3])))\n",
    "    # 4->marital-status  \n",
    "    d.append(mean_semantic(D[:,4], 'marital-status'))\n",
    "    # 5->occupation  \n",
    "    d.append(mean_semantic(D[:,5], 'occupation'))\n",
    "    # 6->relationship \n",
    "    d.append(mean_semantic(D[:,6], 'relationship'))\n",
    "    # 7->race    \n",
    "    d.append(mean_semantic(D[:,7], 'race'))\n",
    "    # 8->sex  \n",
    "    d.append(mean_semantic(D[:,8], 'sex'))\n",
    "    # 9->capital-gain  \n",
    "    d.append(float(np.mean(D[:,9])))\n",
    "    #10->capital-loss \n",
    "    d.append(float(np.mean(D[:,10])))\n",
    "    #11->hours-per-week \n",
    "    d.append(float(np.mean(D[:,11])))\n",
    "    #12->native-country  \n",
    "    d.append(mean_semantic(D[:,12], 'native-country'))\n",
    "    \n",
    "    return d\n",
    "    \n",
    "def mean_semantic(values, attribute_name):\n",
    "    candidates = list(distances[attribute_name].keys())\n",
    "    return values[np.argmin([sum([distances[attribute_name][c][v] for c in candidates]) for v in values])]\n",
    "\n",
    "def dist(x,y):\n",
    "    return np.linalg.norm(x-y)\n",
    "    #return scipy.spatial.distance.correlation(x,y)\n",
    "\n",
    "def poprow(arr,i):\n",
    "    pop = arr[i]\n",
    "    new_array = np.vstack((arr[:i],arr[i+1:]))\n",
    "    return new_array,pop\n",
    "\n",
    "def cluster(X, p, k):\n",
    "    c = [p]\n",
    "    D = np.column_stack((X,[dist_record(v[:-1],p[:-1]) for v in X]))\n",
    "    D = D[D[:,-1].argsort()]\n",
    "    D = np.delete(D, -1, 1)\n",
    "    c.extend(D[:k-1])\n",
    "    D = D[k-1:]\n",
    "    \n",
    "    xc = np.array([p[:-1] for p in c], copy=False, ndmin=2)\n",
    "    yc = np.array([p[-1] for p in c], copy=False)\n",
    "    cl = (xc, yc)\n",
    "    return D, cl\n",
    "    \n",
    "def mdav(X, y, k):\n",
    "    D = np.column_stack((X,y))\n",
    "    clusters = []\n",
    "    while len(D) >= 3*k:\n",
    "        # Centroid\n",
    "        xm = mean_record(D)\n",
    "        # Furthest from centroid\n",
    "        xri = np.argmax([dist_record(v[:-1],xm) for v in D])\n",
    "        D, xr = poprow(D, xri)\n",
    "        # Furthest from furthest from centroid\n",
    "        xsi = np.argmax([dist_record(v[:-1],xr[:-1]) for v in D])\n",
    "        D, xs = poprow(D, xsi) \n",
    "\n",
    "        #cluster of xr\n",
    "        D, c = cluster(D, xr, k)\n",
    "        clusters.append(c)\n",
    "        #cluster of xs\n",
    "        D, c = cluster(D, xs, k)\n",
    "        clusters.append(c)\n",
    "        \n",
    "    if len(D) >= 2*k and len(D) < 3*k:\n",
    "        # Centroid\n",
    "        xm = mean_record(D)\n",
    "        # Furthest from centroid\n",
    "        xri = np.argmax([dist_record(v[:-1],xm) for v in D])\n",
    "        D, xr = poprow(D, xri)\n",
    "        #cluster of xr\n",
    "        D, c = cluster(D, xr, k)\n",
    "        clusters.append(c)\n",
    "        \n",
    "        # rest of points\n",
    "        xc = np.array([p[:-1] for p in D[:]], copy=False, ndmin=2)\n",
    "        yc = np.array([p[-1] for p in D[:]], copy=False)\n",
    "        cl = (xc, yc)\n",
    "        clusters.append(cl)     \n",
    "    else:\n",
    "        # rest of points\n",
    "        xc = np.array([p[:-1] for p in D[:]], copy=False, ndmin=2)\n",
    "        yc = np.array([p[-1] for p in D[:]], copy=False)\n",
    "        cl = (xc, yc)\n",
    "        clusters.append(cl)\n",
    "    \n",
    "    centroids = np.array([mean_record(c[0]) for c in clusters], copy=False)\n",
    "    \n",
    "    return clusters, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [5]\n",
    "clusterings = []\n",
    "centroids_of_clusterings = []\n",
    "for k in K:\n",
    "    clustering, centroids = mdav(X, y, k)\n",
    "    clusterings.append(clustering)\n",
    "    centroids_of_clusterings.append(centroids)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for i in range(0, len(centroids), 10):\n",
    "    if np.any(clustering[i][1] != clustering[i][1][0]):\n",
    "        idxs.append(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
