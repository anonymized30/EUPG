{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "headers = ['age','workclass','fnlwgt','education','education-num','marital-status',\n",
    "           'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "           'hours-per-week','native-country','class']\n",
    "\n",
    "adult = pd.read_csv('adult/adult.data', \n",
    "                    sep=', ', names=headers, na_values='?', engine='python')\n",
    "\n",
    "# Drop all records with missing values\n",
    "adult.dropna(inplace=True)\n",
    "\n",
    "y = adult['class'].to_numpy()\n",
    "X = adult.drop(['fnlwgt', 'class'], axis = 1)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Specify the file names for saving\n",
    "file_X_train = \"adult/X_train_nc.csv\"\n",
    "file_X_test = \"adult/X_test_nc.csv\"\n",
    "file_y_train = \"adult/y_train_nc.pkl\"\n",
    "file_y_test = \"adult/y_test_nc.pkl\"\n",
    "\n",
    "# Save the data to the adult directory\n",
    "X_train.to_csv(file_X_train, index=False)\n",
    "X_test.to_csv(file_X_test, index=False)\n",
    "with open(file_y_train, 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(file_y_test, 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load semantic distances from files\n",
    "import os\n",
    "import collections\n",
    "categorical_attributes = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                          'relationship','race','sex','native-country']\n",
    "# path = 'semdist/ontodist/'\n",
    "path = 'semdist/embedist/'\n",
    "\n",
    "distances = {}\n",
    "for categorical_attribute in categorical_attributes:\n",
    "    with open(path+categorical_attribute+'.txt') as f:\n",
    "        contents = list(f)\n",
    "        categories = list(map(str.strip, contents[0].split(',')))\n",
    "        m = []\n",
    "        for line in contents[1:]:\n",
    "            m.append(list(map(float, map(str.strip, line.split(',')))))\n",
    "        d = collections.defaultdict(dict)\n",
    "        for i in range(len(categories)):\n",
    "            for j in range(len(categories)):\n",
    "                d[categories[i]][categories[j]] = m[i][j]\n",
    "        distances[categorical_attribute] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_attr(x, y, attr_pos, categorical_mask, column_names):\n",
    "    if categorical_mask[attr_pos]:\n",
    "        return distances[column_names[attr_pos]][x[attr_pos]][y[attr_pos]]\n",
    "    else:\n",
    "        return abs(float(x[attr_pos]) - float(y[attr_pos]))\n",
    "\n",
    "def dist_record(x, y):\n",
    "    d = []\n",
    "    categorical_mask = [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
    "    column_names =  ['age','workclass','education','education-num','marital-status',\n",
    "           'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "           'hours-per-week','native-country']\n",
    "    for i, cn in enumerate(column_names):\n",
    "        d.append(dist_attr(x, y, i, categorical_mask, column_names))\n",
    "    \n",
    "    return float(sum(d))\n",
    "    \n",
    "def mean_record(D):\n",
    "    d = []\n",
    "    # 0->age \n",
    "    d.append(float(np.mean(D[:,0])))\n",
    "    # 1->workclass  \n",
    "    d.append(mean_semantic(D[:,1], 'workclass'))\n",
    "    # 2->education \n",
    "    d.append(mean_semantic(D[:,2], 'education'))\n",
    "    # 3->education-num   \n",
    "    d.append(float(np.mean(D[:,3])))\n",
    "    # 4->marital-status  \n",
    "    d.append(mean_semantic(D[:,4], 'marital-status'))\n",
    "    # 5->occupation  \n",
    "    d.append(mean_semantic(D[:,5], 'occupation'))\n",
    "    # 6->relationship \n",
    "    d.append(mean_semantic(D[:,6], 'relationship'))\n",
    "    # 7->race    \n",
    "    d.append(mean_semantic(D[:,7], 'race'))\n",
    "    # 8->sex  \n",
    "    d.append(mean_semantic(D[:,8], 'sex'))\n",
    "    # 9->capital-gain  \n",
    "    d.append(float(np.mean(D[:,9])))\n",
    "    #10->capital-loss \n",
    "    d.append(float(np.mean(D[:,10])))\n",
    "    #11->hours-per-week \n",
    "    d.append(float(np.mean(D[:,11])))\n",
    "    #12->native-country  \n",
    "    d.append(mean_semantic(D[:,12], 'native-country'))\n",
    "    \n",
    "    return d\n",
    "    \n",
    "def mean_semantic(values, attribute_name):\n",
    "    candidates = list(distances[attribute_name].keys())\n",
    "    return values[np.argmin([sum([distances[attribute_name][c][v] for c in candidates]) for v in values])]\n",
    "\n",
    "def dist(x,y):\n",
    "    return np.linalg.norm(x-y)\n",
    "    #return scipy.spatial.distance.correlation(x,y)\n",
    "\n",
    "def poprow(arr,i):\n",
    "    pop = arr[i]\n",
    "    new_array = np.vstack((arr[:i],arr[i+1:]))\n",
    "    return new_array,pop\n",
    "\n",
    "def cluster(X, p, k):\n",
    "    c = [p]\n",
    "    D = np.column_stack((X,[dist_record(v[:-1],p[:-1]) for v in X]))\n",
    "    D = D[D[:,-1].argsort()]\n",
    "    D = np.delete(D, -1, 1)\n",
    "    c.extend(D[:k-1])\n",
    "    D = D[k-1:]\n",
    "    \n",
    "    xc = np.array([p[:-1] for p in c], copy=False, ndmin=2)\n",
    "    yc = np.array([p[-1] for p in c], copy=False)\n",
    "    cl = (xc, yc)\n",
    "    return D, cl\n",
    "    \n",
    "def mdav(X, y, k):\n",
    "    D = np.column_stack((X,y))\n",
    "    clusters = []\n",
    "    while len(D) >= 3*k:\n",
    "        # Centroid\n",
    "        xm = mean_record(D)\n",
    "        # Furthest from centroid\n",
    "        xri = np.argmax([dist_record(v[:-1],xm) for v in D])\n",
    "        D, xr = poprow(D, xri)\n",
    "        # Furthest from furthest from centroid\n",
    "        xsi = np.argmax([dist_record(v[:-1],xr[:-1]) for v in D])\n",
    "        D, xs = poprow(D, xsi) \n",
    "\n",
    "        #cluster of xr\n",
    "        D, cl = cluster(D, xr, k)\n",
    "        clusters.append(cl)\n",
    "        #cluster of xs\n",
    "        D, cl = cluster(D, xs, k)\n",
    "        clusters.append(cl)\n",
    "        \n",
    "    if len(D) >= 2*k and len(D) < 3*k:\n",
    "        # Centroid\n",
    "        xm = mean_record(D)\n",
    "        # Furthest from centroid\n",
    "        xri = np.argmax([dist_record(v[:-1],xm) for v in D])\n",
    "        D, xr = poprow(D, xri)\n",
    "        #cluster of xr\n",
    "        D, cl = cluster(D, xr, k)\n",
    "        clusters.append(cl)\n",
    "        \n",
    "        # rest of points\n",
    "        xc = np.array([p[:-1] for p in D[:]], copy=False, ndmin=2)\n",
    "        yc = np.array([p[-1] for p in D[:]], copy=False)\n",
    "        cl = (xc, yc)\n",
    "        clusters.append(cl)     \n",
    "    else:\n",
    "        # rest of points\n",
    "        xc = np.array([p[:-1] for p in D[:]], copy=False, ndmin=2)\n",
    "        yc = np.array([p[-1] for p in D[:]], copy=False)\n",
    "        cl = (xc, yc)\n",
    "        clusters.append(cl)\n",
    "    \n",
    "    centroids = np.array([mean_record(c[0]) for c in clusters], copy=False)\n",
    "    \n",
    "    return clusters, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awsna\\AppData\\Local\\Temp\\ipykernel_12832\\3147368950.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  X_train_k = np.vstack(np.repeat(centroids[i].reshape(1, -1), len(c[0]), axis = 0) for i, c in enumerate(clustering))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 5\n",
      "k= 10\n",
      "k= 15\n",
      "k= 20\n"
     ]
    }
   ],
   "source": [
    "K = [3, 5, 10, 15, 20]\n",
    "for k in K:\n",
    "    print('k=', k)\n",
    "    clustering, centroids = mdav(X_train, y_train, k)\n",
    "    X_train_k = np.vstack(np.repeat(centroids[i].reshape(1, -1), len(c[0]), axis = 0) for i, c in enumerate(clustering))\n",
    "    \n",
    "    y_train_k = None\n",
    "    for i in range(len(clustering)):\n",
    "        yc = clustering[i][1]\n",
    "        if y_train_k is None:\n",
    "            y_train_k = yc\n",
    "        else:\n",
    "            y_train_k = np.hstack((y_train_k, yc))\n",
    "    \n",
    "    X_train_k = pd.DataFrame(X_train_k, columns = X_train.columns)\n",
    "    categorical_mask = [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
    "    for mask, col in zip(categorical_mask, X_train_k.columns):\n",
    "        if mask == 0: \n",
    "            X_train_k[col] = pd.to_numeric(X_train_k[col], errors='coerce')\n",
    "    # Specify the file names for saving\n",
    "    file_X_train_k = \"adult/X_train_nc_k={}.csv\".format(k)\n",
    "    file_y_train_k = \"adult/y_train_nc_k={}.pkl\".format(k)\n",
    "\n",
    "    # Save the data to the adult directory\n",
    "    X_train_k.to_csv(file_X_train_k, index=False)\n",
    "    \n",
    "    with open(file_y_train_k, 'wb') as f:\n",
    "        pickle.dump(y_train_k, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
